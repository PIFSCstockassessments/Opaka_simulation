---
title: "Creating the OMs"
format: html
---


```{r}
library(r4ss)
library(tidyverse)
library(ss3sim)
library(stringr)
main.dir <- this.path::here(.. = 1)
source(file.path(main.dir, "R", "simF.r"))
source(file.path(main.dir, "R", "make_dummy_dat.r"))
source(file.path(main.dir, "R", "get_fits.r"))
set.seed <- read.csv(file.path(main.dir, "Inputs", "setseed.csv"))
niter <- 10
rep <- SS_output(dir = file.path(main.dir, "models", "03-simplified-mod"))
```


### Create rec dev timeseries
Use estimated rec devs from "03-simplified-mod" but add some noise to the last 10 years. Then simulate future recruitment trajectories. Future_recdevs is stable recruitment devs centered around 0 with an sd of 0.16. Poor_recdevs simulates declining productivity by ~30% over the first 20 years and then stable, low productivity for the next 30 years. 
```{r}
recdevs_df <- rep$parameters %>% 
filter(str_detect(Label, "Rec")) %>% 
select(c(Label, Value)) %>% 
separate(col = Label, sep = "_", into = c("period", "recdev", "year")) 

plot(x = recdevs_df$year, y = recdevs_df$Value, type = "l")
sigmar <- .657 #from opaka model
new_recdevs <- matrix(data = NA, nrow = nrow(recdevs_df)+1, ncol = 100)
new_recdevs[1,] <- 0
for(i in 2:nrow(new_recdevs)){
    if(i < 60){
        recdev_sd <- .01
        new_recdevs[i,] <- faux::rnorm_multi(n = 100, ## year vector
                                 vars = 1,
                                 mu = recdevs_df$Value[i-1],
                                 r = 1-1e-5, #correlation
                                 sd = recdev_sd)[,1]
    }else{
        recdev_sd <- 0.14 #(sigmar^2/2 lognormal bias correction?)
        recdevs <- rnorm(n = 100, mean = 0, sd = sigmar)  
        new_recdevs[i,] <- sigmar * recdevs - sigmar^2 / 2 
        # new_recdevs[i,] <- faux::rnorm_multi(n = 100, ## year vector
        #                          vars = 1,
        #                          mu = 0,
        #                          r = 1-1e-5, #correlation
        #                          sd = recdev_sd)[,1]
    }


}
matplot(new_recdevs, type = "l")

# png(file.path(main.dir, "Model_Runs", '2024-12-03-rdevs_array.png'), height = 8, width =8, unit = 'in', res =400)
matplot(y = new_recdevs, type = "l", lty = 1, lwd = 1.2)
abline(h = 0)
#lines(x = 2:75, y = recdevs_df$Value, col = "red", lwd = 2, lty = 2)
# dev.off()
# save(list = "new_recdevs", file = file.path(main.dir, "Inputs", "recdevs_mat.RData"))

future_recdevs <- matrix(data = NA, nrow = 50, ncol = 100)
for(i in 1:nrow(future_recdevs)){ 
    recdevs <- rnorm(n = 100, mean = 0, sd = 0.)   
    future_recdevs[i,] <- sigmar * recdevs - sigmar^2 / 2 
}
matplot(y = future_recdevs, type = "l")

full_recdevs <- rbind(new_recdevs, future_recdevs)
# save(list = "full_recdevs", file = file.path(main.dir, "Inputs", "recdevs_mat.RData"))
matplot(y = full_recdevs, type = "l")

## years of poor recruitment in the future
poor_recdevs <- matrix(data = NA, nrow = 50, ncol = 100)
#vector of declining mu, declines by 40% over 25 years
mu.vec <- sort(stats::runif(n=20,min = -.40,max=0), decreasing =T)
recdev_sd <- .52 #half of sigmaR? Check about log scale
plot(x = 1:20, y = mu.vec, type = "l")
for(i in 1:nrow(poor_recdevs)){
    if(i <= 20){
        recdevs <- rnorm(n = 100, mean = mu.vec[i], sd = recdev_sd)  
        poor_recdevs[i,] <- recdev_sd * recdevs - recdev_sd^2 / 2 
        
    }else{
        recdevs <- rnorm(n = 100, mean = -.4, sd = recdev_sd)  
        poor_recdevs[i,] <- recdev_sd * recdevs - recdev_sd^2 / 2
    }

}

matplot(y = poor_recdevs, type = "l")
full_poor_recdevs <- rbind(new_recdevs, poor_recdevs) #same recdevs for years 1-75 as full_recdevs, then add poor recdevs for future
matplot(y = full_poor_recdevs, type = "l")
abline(h = 0)
abline(v=76)
abline(v=95)
# lines(x = 76:95, y = mu.vec, lty = 2, col = "red")
# save(list = "full_poor_recdevs", file = file.path(main.dir, "Inputs", "poor_recdevs_mat.RData"))

# recdev_sd <- 0.2
# poor_recdevs <- matrix(data = NA, nrow = 50, ncol = 100)
# for(i in 1:nrow(poor_recdevs)){ 
#     poor_recdevs[i,] <- faux::rnorm_multi(n = 100, ## year vector
#                                 vars = 1,
#                                 mu = -.2,
#                                 r = 1-1e-5, #correlation
#                                 sd = recdev_sd)[,1]
# }
# matplot(y = poor_recdevs, type = "l")
# abline(h = 0)

# full_poor_recdevs <- rbind(full_recdevs[1:75,], poor_recdevs) #same recdevs for years 1-75 as full_recdevs, then add poor recdevs for future
# matplot(y = full_poor_recdevs, type = "l")
# abline(h = 0)
# save(list = "full_poor_recdevs", file = file.path(main.dir, "Inputs", "poor_recdevs_mat.RData"))
```

## Simulating F trajectory
```{r}
for(i in 1:nrow(future_cf)){ 
    future_cf[i,] <- faux::rnorm_multi(n = 100, ## year vector
                                vars = 1,
                                mu = 0.0325262, # terminal year F from model
                                r = 1-1e-5, #correlation
                                sd = 0.0075)[,1]
}
matplot(y = future_cf, type = "l", lty = 1, lwd = 1.2)
F_comm_mod <- rep$exploitation$Comm[-1]
F_comm_df <- matrix(data = rep(F_comm_mod, 100), nrow = 75, ncol = 100,byrow = F)
F_comm_df <- rbind(F_comm_df, future_cf)
F_noncomm_mod <- rep$exploitation$Non_comm[-1]
F_noncomm_df <- matrix(data = rep(F_noncomm_mod, 100), nrow = 75, ncol = 100,byrow = F)
F_noncomm_df <- rbind(F_noncomm_df, future_cf * 1.03)
# save(list = c("F_noncomm_df", "F_comm_df"), file = file.path(main.dir, "Inputs", "constantF_mat.RData"))

## Increasing F
F_up_mu <- seq(F_comm_mod[75], 0.0491544, length.out = 20) #increase back up to 75 percentile of historical Fs
future_F_up <- matrix(data = NA, nrow = 50, ncol = 100)
for(i in 1:nrow(future_F_up)){
    if(i <=20){
         future_F_up[i, ] <- faux::rnorm_multi(n = 100, ## year vector
                                vars = 1,
                                mu = F_up_mu[i], # increasing F trajectory
                                r = 1-1e-5, #correlation
                                sd = 0.0015)[,1]
    }else{
        future_F_up[i, ] <- faux::rnorm_multi(n = 100, ## year vector
                            vars = 1,
                            mu = F_up_mu[20], # stay around the last year of increasing 
                            r = 1-1e-5, #correlation
                            sd = 0.0015)[,1]
    }

}
matplot(y = future_F_up, type = "l", lty = 1, lwd = 1.2)
F_comm_up <- rbind(F_comm_df, future_F_up)
F_noncomm_up <- rbind(F_noncomm_df, future_F_up * 1.03)
# save(list = c("F_noncomm_up", "F_comm_up"), file = file.path(main.dir, "Inputs", "increaseF_mat.RData"))
```

### Load already created RecDev-vectors and get F from simplified model
```{r}
F_comm_mod <- rep$exploitation$Comm[-1]
F_noncomm_mod <- rep$exploitation$Non_comm[-1]
load(file.path(main.dir, "Inputs", "recdevs_mat.RData"))
load(file.path(main.dir, "Inputs", "poor_recdevs_mat.RData"))
load(file.path(main.dir, "Inputs", "constantF_mat.RData"))
load(file.path(main.dir, "Inputs", "increaseF_mat.RData"))
```


### Creating scenario variables
```{r}
#steepness
h_vec <- c(0.5, 0.76, 0.85)
#unreported catch ratios 
u_vec <- c(rep(1.8, 26), rep(1.47, 29), rep(1.03, 20))
##TODO: sampling vectors for catch, index, length and age comp data 
```

### Create starting OM and EMs for a scenario

This loop can be run for each scenario to create the starting OM and EMs. To distinguish between sampling scenarios, change the `scenarios` argument in `ss3sim_base()`. 

```{r}

#recdev0 <- matrix(data = 0, nrow = 75, ncol = niter) #for testing deterministic runs with no rec-devs
nyears <- 75
nyears_fwd <- 0
om_dir <- file.path(main.dir, "models", paste0("opaka-om"))#, nyears_fwd)) #-5 -15 -25 -50
em_dir <- file.path(main.dir, "models", paste0("opaka-em"))#, nyears_fwd)) #-5 -15 -25 -50

scen <- "no_var"
sas <- sas_full %>% filter(Scen_name == scen)

for(I in 11:niter){
    # Get F-vector 
   # F_noncomm <- u_vec * F_vec_mat[I,]
    F_list <- list(
        years = list(1:nyears, 1:nyears),
        fleets = c(1, 2), 
        fvals = list(F_comm_df[1:nyears,I], F_noncomm_df[1:nyears,I])
        )
    #create sampling scheme for indices of abundance
    index <- list(
        fleets = c(1, 3), 
        years = list(seq(1, nyears, by = 1), seq(69, nyears, by = 1)),
        seas = list(7,1), 
        sds_obs = list(0.01, sas[which(sas$N_years == nyears_fwd), "Resfish_index_CV"]) 
    )

    lcomp <- list(
        fleets = c(3), Nsamp = list(100),
        years = list(seq(69, nyears, by = 1))
    )

    agecomp <- list(
        fleets = c(3), Nsamp = list(sas[which(sas$N_years == nyears_fwd), "Neff_age_Resfish"]),
        years = list(seq(69, nyears, by = 1))
    )
    
    seed <- set.seed[I,2]

    ss3sim_base(
        iterations = I,
        scenarios = paste(scen, nyears_fwd, "yrfwd", sep = "_"), 
        f_params = F_list,
        index_params = index,
        lcomp_params = lcomp,
        #agecomp_params = agecomp,
        om_dir = om_dir,
        em_dir = em_dir,
        user_recdevs = full_recdevs,
        bias_adjust = T,
        seed = seed,
        extra = "-nohess"
    )

    om_dat <- SS_readdat_3.30(file = file.path(main.dir, "Model_Runs", I, "om", "ss3.dat"))
    om_dat$Nsexes <- -1
    SS_writedat(om_dat, file.path(main.dir, "Model_Runs", I, "om", "ss3.dat"), overwrite = T)
    r4ss::run(dir = file.path(main.dir, "Model_Runs", I, "om"), exe = "ss", extras = "-nohess", skipfinished = F)

    em_dat <- SS_readdat_3.30(file = file.path(main.dir, "Model_Runs", I, "em", "ss3.dat"))
    em_dat$Nsexes <- -1
    SS_writedat(em_dat, file.path(main.dir, "Model_Runs", I, "em", "ss3.dat"), overwrite = T)
    r4ss::run(dir = file.path(main.dir, "Model_Runs", I, "em"), exe = "ss", skipfinished = F)
    rm(list = c("om_dat", "em_dat"))
    

}


rep <- SS_output(file.path(main.dir, "SQ_0_yrfwd", "1", "em"))
SS_plots(rep)
dat <- SS_readdat_3.30(file.path(main.dir, "SQhyperstable_15_yrfwd", "1", "om", "data_expval.ss"))
cpue <- dat$CPUE %>% filter(index == 1) %>% pull(obs)
beta.1 <- .25
means <- dat$CPUE %>% filter(index ==1 & year > 75) %>% summarise(mvb = mean(obs), mvbb = mean(obs^beta.1))

hscpue <- c(cpue[1:75],(cpue[76:90]^beta.1)*(means$mvb[1]/means$mvbb[1]))
plot(x = 1:90, y = cpue, type = "l")
lines(x = 1:90, y = hscpue, col = "orange")

reps <- SSgetoutput(dirvec = c(#file.path(main.dir, "SQ_15_yrfwd", "1", "om"),
file.path(main.dir, "no_var_0_yrfwd", "1", "om"),
file.path(main.dir, "no_var_0_yrfwd", "1", "em")
))

rep_1 <- SS_output(dir = dir, covar = FALSE, verbose = FALSE,
    forecast = forecastTF, warn = FALSE,
    readwt = FALSE, printstats = FALSE, NoCompOK = TRUE)
reps <- SSgetoutput(dirvec = c(
#  file.path(main.dir, "HRFhyperstable_15_yrfwd", "1", "om"),
#  file.path(main.dir, "HRFhyperstable_15_yrfwd", "1", "em"),
#  file.path(main.dir, "HRFhyperstable_15_yrfwd", "2", "om"),
#  file.path(main.dir, "HRFhyperstable_15_yrfwd", "2", "em"),
#  file.path(main.dir, "HRFhyperstable_15_yrfwd", "3", "om"),
#  file.path(main.dir, "HRFhyperstable_15_yrfwd", "3", "em"),
#  file.path(main.dir, "HRFhyperstable_15_yrfwd", "4", "om"),
#  file.path(main.dir, "HRFhyperstable_15_yrfwd", "4", "em"),
#  file.path(main.dir, "HRFhyperstable_15_yrfwd", "5", "om"),
#  file.path(main.dir, "HRFhyperstable_15_yrfwd", "5", "em")
# file.path(main.dir, "SQpoorrec_15_yrfwd", "1", "om"),
# file.path(main.dir, "SQpoorrec_15_yrfwd", "1", "em"),
# file.path(main.dir, "SQpoorrec_15_yrfwd", "2", "om"),
# file.path(main.dir, "SQpoorrec_15_yrfwd", "2", "em"),
# file.path(main.dir, "SQpoorrec_15_yrfwd", "3", "om"),
# file.path(main.dir, "SQpoorrec_15_yrfwd", "3", "em"),
# file.path(main.dir, "SQpoorrec_15_yrfwd", "4", "om"),
# file.path(main.dir, "SQpoorrec_15_yrfwd", "4", "em"),
# file.path(main.dir, "SQpoorrec_15_yrfwd", "5", "om"),
# file.path(main.dir, "SQpoorrec_15_yrfwd", "5", "em")
# file.path(main.dir, "SQpoorrec_15_yrfwd", "6", "om"),
# file.path(main.dir, "SQpoorrec_15_yrfwd", "6", "em"),
# file.path(main.dir, "SQpoorrec_15_yrfwd", "7", "om"),
# file.path(main.dir, "SQpoorrec_15_yrfwd", "7", "em")
#  file.path(main.dir, "SQ_0_yrfwd", "1", "om"),
#  file.path(main.dir, "SQ_0_yrfwd", "1", "em"),
 file.path(main.dir, "SQ_0_yrfwd", "11", "om"),
 file.path(main.dir, "SQ_0_yrfwd", "11", "em"),
 file.path(main.dir, "SQ_0_yrfwd", "12", "om"),
 file.path(main.dir, "SQ_0_yrfwd", "12", "em"),
 file.path(main.dir, "SQ_0_yrfwd", "13", "om"),
 file.path(main.dir, "SQ_0_yrfwd", "13", "em"),
 file.path(main.dir, "SQ_0_yrfwd", "14", "om"),
 file.path(main.dir, "SQ_0_yrfwd", "14", "em"),
 file.path(main.dir, "SQ_0_yrfwd", "15", "om"),
 file.path(main.dir, "SQ_0_yrfwd", "15", "em")
))

mod_dirs <- list.dirs(path = file.path(main.dir, "SQ_0_yrfwd"), full.names = T, recursive = T)
om_em_dirs <- mod_dirs[str_detect(mod_dirs, "om|em")]
om_em_dirs <- om_em_dirs[str_detect(om_em_dirs, "bias_00", negate = T)]
reps <- SSgetoutput(dirvec = om_em_dirs[c(1,2,25,26,47,48,69,70,91,92, 113, 114, 135, 136,157,158,179,180,3,4)])
reps_sum <- SSsummarize(reps)
SSplotComparisons(reps_sum, legendlabels = c("om1", "em1", "om2", "em2", "om3", "em3", "om4", "em4", "om5", "em5"))
SSplotComparisons(reps_sum, legendlabels = c("reg_om", "reg_em", "poorrec_om", "hyperstable_em"), print = T, plotdir = main.dir)

SSplotComparisons(reps_sum, col = c(1,1,2,2,3,3,4,4,5,5), lty = rep(c(1,2), 5))
SSplotComparisons(reps_sum, models = c(1,2,25,26,47,48,69,70,91,92), subplots = c(1,7,9,11,13)) 
SS_plots(reps$replist4)
SS_plots(reps$replist8)

reps$replist2$breakpoints_for_bias_adjustment_ramp
new_bias <- SS_fitbiasramp(reps$replist4)

reps_sum$indices %>% filter(Fleet == 3) %>% #filter(name == "replist1" | name == "replist2") %>%
mutate(name = recode(name, 
                    replist1 = "om_1", 
                    replist2 = "em_1", 
                    replist3 = "om_2",
                    replist4 = "em_2",
                    replist5 = "om_3",
                    replist6 = "em_3",
                    replist7 = "om_4",
                    replist8 = "em_4",
                    replist9 = "om_5",
                    replist10 = "em_5"
                    )) %>%
separate(name, sep = "_", into = c("mod_type", "rep")) %>%
ggplot(aes(x = Yr)) +
geom_point(data = . %>% filter(mod_type == "om"), aes(y = Exp, color = mod_type)) + 
geom_point(data = . %>% filter(mod_type == "em"), aes(y = Obs, color = mod_type)) + 
geom_line(data = . %>% filter(mod_type == "em"), aes(y = Exp, color = mod_type), linewidth = 1.5) +
facet_wrap(~rep) +
labs(x = "Year", y = "BFISH Index") + 
theme_classic() +
theme(legend.position = "top",
legend.text = element_text(size = 12))

```

## Adding future data to model 
I will add years of future data to the model based on simulated F's. I can simulate different possible F scenarios for the future, e.g. what if F increases over the next 50 years? what if F is constant over the next 50 years? Those F's will be added on to the F vector used right now and the same ss3sim_base function can be used to create a new EM. 
Notes for self: 
*   composition sample size - think in terms of stage-1 and stage-2. Stage-1 is input sample size and can be by number of hauls (or PSUs) or landing (Nfish sampled from fishery) (Punt et al 2021)
*   Should age-comp data actually be CAAL? Probably. Good question to talk to Felipe and Eva about
*   Fishery comp data _should_ be collected proportionally to catch, spatially and temporally. If the model isn't spatial, length comp data should be catch-weighted to obtain most representative data of the whole fishery


Questions from Punt et al. 2021 to think about for this project:
1. How does the ability to estimate quantities of management interest change with average annual (effective) sample sizes for length-comp and conditional age-length data? 
~~2. Does including data sources with small sample sizes in an assessment lead to bias? ~~
3. What are the implications of collecting length and age samples at intervals greater than one year but large sample sizes?
~~4. How does the assessment performance change if sampling is unbalanced over time and space?~~
Questions from Ono et al. 2015
1. What is the value of age vs length composition data? 
2. What is the influence of age composition collection frequency and duration?
3. What is the influence of frequency and duration of survey composition data?
4. What is the impact of historical fishery composition data? 
5. What is the impact of composition data sample size? 
6. Which fishing pattern produces the most informative data? 


```{r}
n_yrs_fwd <- 5
Iteration <- 1 #iteration
for(Iteration in 6:niter){

## Create new OM directory
om_I <- paste0("om_", n_yrs_fwd) 
new_OM_dir <- file.path(main.dir, "opaka-sim", Iteration, om_I) #TODO: will need to generalize om_2 somehow
dir.create(new_OM_dir)
files_list <- c("ss3.dat", "om.ctl", "forecast.ss", "starter.ss", "ss.exe")
file.copy(from = file.path(main.dir, "opaka-sim", Iteration, "om", files_list), 
to = new_OM_dir, overwrite = T)
##read in OM 
om_dat <- SS_readdat_3.30(file = file.path(new_OM_dir, "ss3.dat"))
endyr <- om_dat$endyr
new_endyr <- endyr+n_yrs_fwd

##update recdevs
om_ctl <- SS_readctl_3.30(file = file.path(new_OM_dir, "om.ctl"), datlist = om_dat)

om_ctl$MainRdevYrLast <- new_endyr
om_ctl$last_yr_fullbias_adj <- new_endyr
om_ctl$first_recent_yr_nobias_adj <- new_endyr
om_ctl$N_Read_recdevs <- new_endyr
om_ctl$recdev_input <- bind_rows(om_ctl$recdev_input, 
data.frame(Year = seq(endyr+1, new_endyr), 
recdev = rdevs_array[(endyr+1):new_endyr,Iteration]))

## dataframe of new F to add to OM 
new_f <- om_ctl$F_setup2 %>% 
slice(rep(n(), each = n_yrs_fwd), .by = fleet) %>% 
mutate(yr = rep(seq(endyr+1,new_endyr), 2)) %>%
bind_rows(om_ctl$F_setup2) %>% 
arrange(fleet, yr)
F_comm <- new_f %>% filter(fleet == 1) %>% pull(Fvalue)
F_non_comm <- new_f %>% filter(fleet == 2) %>% pull(Fvalue)
newctl <- ss3sim::change_f(years = list(1:new_endyr,1:new_endyr), fleets = c(1,2), fvals = list(F_comm, F_non_comm), ctl_list = om_ctl)

#save new ctl file
SS_writectl(newctl, file.path(new_OM_dir, "om.ctl"), overwrite = T)

##add dummy data rows to data file
om_dat$endyr <- new_endyr
## catch
om_dat$catch <- make_dummy_dat_catch(fleets = c(1,2), years = 1:new_endyr)
## cpue
om_dat$CPUE <- bind_rows(
    make_dummy_dat_cpue(fleets = 1, years = 1:new_endyr, seas = 7),
    make_dummy_dat_cpue(fleets = 3, years = 69:new_endyr, seas = 1)
)
## length comp 
om_dat$lencomp <- bind_rows(
        make_dummy_dat_lencomp(fleets = 1, years = c(76:new_endyr), len_bins = om_dat$lbin_vector, nsex = 1),
        make_dummy_dat_lencomp(fleets = 3, years = c(69:new_endyr), len_bins = om_dat$lbin_vector, nsex = 1)
    )
## age comp 
om_dat$agecomp <- bind_rows(
        make_dummy_dat_agecomp(fleets = 1, years = c(76:new_endyr), age_bins = om_dat$agebin_vector, nsex = 1),
        make_dummy_dat_agecomp(fleets = 3, years = c(69:new_endyr), age_bins = om_dat$agebin_vector, nsex = 1)
    )
#save new dat file
SS_writedat(om_dat, file.path(new_OM_dir, "ss3.dat"), overwrite = T)

#run OM 
r4ss::run(dir = new_OM_dir, exe = "ss", extras = "-nohess", skipfinished = F)

## Create new EM directory 
em_I <- paste0("em_", n_yrs_fwd)
new_EM_dir <- file.path(main.dir, "opaka-sim", Iteration, em_I) 
dir.create(new_EM_dir)
files_list <- c("em.ctl", "forecast.ss", "starter.ss", "ss.exe")
file.copy(from = file.path(main.dir, "opaka-sim", Iteration, "em", files_list), 
to = new_EM_dir, overwrite = T) #TODO: will need to generalize the em path here
file.copy(from = file.path(main.dir, "opaka-sim", Iteration, "em", "ss3.dat"),
to = new_EM_dir)

## Sample data from OM 
dat_exp <- SS_readdat_3.30(file.path(new_OM_dir, "data_expval.ss"))
### Index data
dat_samp <- ss3sim::sample_index(dat_exp, fleets = c(1,3), years = list(seq(endyr+1, new_endyr), seq(endyr+1, new_endyr)),
sds_obs = list(0.13, 0.25), seas = list(7,1))
samp_ind <- dat_samp$CPUE %>% filter(year > endyr & year <= new_endyr)
### Catch data
dat_samp <- ss3sim::sample_catch(dat_samp) 
samp_catch <- dat_samp$catch %>% filter(year > endyr & year <= new_endyr)
### Lencomp data 
dat_samp <- ss3sim::sample_lcomp(dat_samp, fleets = c(1,3), Nsamp = list(600, 45), years = list(seq(endyr+1, new_endyr), seq(endyr+1, new_endyr))) ##TODO: need to think more about Nsamp, cpar, and ESS
samp_lencomp <- dat_samp$lencomp %>% filter(Yr > endyr & Yr <= new_endyr)
### Agecomp data 
dat_samp <- ss3sim::sample_agecomp(dat_samp, fleets = c(1,3), Nsamp = list(45, 45), years = list(seq(endyr+1, new_endyr), seq(endyr+1, new_endyr))) 
samp_agecomp <- dat_samp$agecomp %>% filter(Yr > endyr & Yr <= new_endyr)
rm("dat_exp")

## Add new sampled data to previous run's data
dat_em <- SS_readdat_3.30(file.path(new_EM_dir, "ss3.dat"))
dat_em$endyr <- new_endyr
dat_em$catch <- dat_em$catch %>% bind_rows(samp_catch) %>% arrange(fleet, year)
dat_em$CPUE <- dat_em$CPUE %>% bind_rows(samp_ind) %>% arrange(index, year)
dat_em$lencomp <- dat_em$lencomp %>% bind_rows(samp_lencomp) %>% arrange(FltSvy, Yr)
dat_em$agecomp <- dat_em$agecomp %>% bind_rows(samp_agecomp) %>% arrange(FltSvy, Yr)
## Save new data file 
SS_writedat_3.30(dat_em, outfile = file.path(new_EM_dir, "ss3.dat"), overwrite = TRUE)

##update last year of recdevs
ctl_em <- SS_readctl_3.30(file = file.path(new_EM_dir, "em.ctl"), datlist = dat_em)
ctl_em$MainRdevYrLast <- new_endyr
SS_writectl(ctl_em, file.path(new_EM_dir, "em.ctl"), overwrite = T)

## Run EM 
r4ss::run(dir = new_EM_dir, exe = "ss", skipfinished = F)

## Calculate recdev bias adjustments and re-run EM 
ss3sim::calculate_bias(dir = new_EM_dir, ctl_file_in = file.path(new_EM_dir, "em.ctl")) #TODO not an exported function 
r4ss::run(dir = new_EM_dir, exe = "ss", skipfinished = F)

## clean up 
rm(list = c("dat_em", "dat_samp", "om_dat", "newctl", "om_ctl"))

} #end of Iteration loop

rep <- SS_output(dir = new_EM_dir)
SS_plots(rep)

```

### Run likelihood profiles
To profile over an F value for a given year, use the following code: 

```{r}
em_I <- "SQ_0_yrfwd"
Iteration <- 5
nyears <- 75
like_dir <- file.path(main.dir, em_I, Iteration, "em", "likelihood_prof")
dir.create(like_dir)
files <- c("ss3.dat", "control.ss_new", "starter.ss", "forecast.ss")
file.copy(from = file.path(main.dir, em_I, Iteration,"em", files), to = like_dir, overwrite = T)
file.copy(from = file.path(main.dir, "bin", "ss3_win.exe"), to = like_dir, overwrite = T)
## Create fvec of values to profile over
rep_tmp <- SS_output(file.path(main.dir, em_I, Iteration, "em"), verbose = F)
fest <- rep_tmp$exploitation %>% filter(Yr == nyears) %>% pull(Comm)
fvec <- seq(fest - 0.01, fest + 0.02, by = 0.001)
fdf <- rep_tmp$exploitation %>% 
select(Yr, Seas, Comm, Non_comm) %>%
pivot_longer(cols = c("Comm", "Non_comm")) %>% 
mutate(Fleet = recode(name, Comm = "1", Non_comm = "2"),
Fleet = as.numeric(Fleet),
se = 0.5,
phase = -1) %>%
filter(Yr > 0) %>%
arrange(Fleet, Yr) %>% 
select(Fleet, Yr, Seas, value, se, phase) 

## Fix selex first 
CTL <- SS_readctl_3.30(file.path(like_dir, "control.ss_new"), datlist = file.path(like_dir, "ss3.dat"))
CTL$size_selex_parms$PHASE <- abs(CTL$size_selex_parms$PHASE) * -1
SS_writectl_3.30(CTL, outfile = file.path(like_dir, "control.ss_new"), overwrite = T)
rm(CTL)
## read in ctl file
CTL <- readLines(file.path(like_dir, "control.ss_new"))
# selex_lines <- grep("#_SizeSelex", CTL)
# end_selex_lines <- grep("#_AgeSelex", CTL)
# selex_params <- CTL[(selex_lines+2):(end_selex_lines-1)]
# selex <- strsplit(selex_params, " ")
# selex_new <- list()
# for(i in 1:length(selex)){
#     ind <- which(selex[[i]] == 3)
#     if(length(ind) == 1){
#         selex[[i]][ind] <- "-3"
#     }
#     selex[[i]] <- selex[[i]][-which(selex[[i]] == "")]
#     selex_new[[i]] <- str_flatten(selex[[i]], collapse =  " ")
# }
# ## replace selex values
# CTL[237] <- selex_new[[1]]
# CTL[238] <- selex_new[[2]]
# CTL[239] <- selex_new[[3]]
# CTL[240] <- selex_new[[4]]
# CTL[241] <- selex_new[[5]]
# CTL[242] <- selex_new[[6]]

## find lines where to break the file and insert new lines
start_ind <- grep("#Fishing Mortality info", CTL)
end_ind <- grep("#_initial_F_parms", CTL)

f_setup <- paste0("## add new fishing mortality info \n",
"#Fishing Mortality info \n",
"0.3 # F ballpark value in units of annual_F \n",
"-2001 # F ballpark year (neg value to disable) \n",
"4 # F_Method:  1=Pope midseason rate; 2=F as parameter; 3=F as hybrid; 4=fleet-specific parm/hybrid (#4 is superset of #2 and #3 and is recommended) \n",
"2.9 # max F (methods 2-4) or harvest fraction (method 1) \n",
"#fleet parameter_value phase \n",
"1 0.015 1 \n",
"2 0.015 1 \n",
"-9998 1 1 \n",
"3 #Ntuning loops \n",
"# detailed setup for F_Method=2; -Yr to fill remaining years \n",
"#Fleet Yr Seas F_value se phase \n")

f_detailed_ender <- " -9999 1 1 1 1 1 \n"


## write out new ctl file
writeLines(CTL[1:(start_ind -1)], file.path(like_dir, "control_modified.ss"))
CON <- file(file.path(like_dir, "control_modified.ss"), "a")
cat(f_setup, file = CON)
write.table(fdf, file = CON, append = T, col.names = F, row.names = F)
cat(f_detailed_ender, file = CON) 
writeLines(CTL[end_ind:length(CTL)], CON)
close(CON)

#adjust se for catch 
dat <- SS_readdat_3.30(file = file.path(like_dir, "ss3.dat"), verbose = F)
dat$catch$catch_se <- .5
SS_writedat(dat, outfile = file.path(like_dir, "ss3.dat"), overwrite = T)
## Create profile directories
profile_dirs <- paste0(like_dir, "/profile_", seq(1,length(fvec)))
sapply(profile_dirs, dir.create)
profile.files <- c("ss3.dat", "control_modified.ss", "starter.ss", "forecast.ss", "ss3_win.exe")
for (i in 1:length(fvec)){
    file.copy(from = file.path(like_dir, profile.files), to = profile_dirs[i], overwrite = T)

    CTL <- readLines(file.path(profile_dirs[i], "control_modified.ss"))
    line_ind <- grep(paste0("1 ",nyears, " 1"), CTL)
    CTL[line_ind] <- paste0("1 ", nyears, " 1 ", fvec[i], " 0.5 -1")
    writeLines(CTL, file.path(profile_dirs[i], "control_modified.ss"))

    START <- SS_readstarter(file.path(profile_dirs[i], "starter.ss"))
    START$ctlfile <- "control_modified.ss"
    START$prior_like <- 1
    START$init_values_src <- 0
    SS_writestarter(START, profile_dirs[i], overwrite = T)

    run(dir = profile_dirs[i], exe = "ss3_win.exe", extras = "-nohess", skipfinished = F, verbose = F)

}



```



```{r}
#em_I <- paste0("em_", n_yrs_fwd)
em_I <- "HRFhyperstable_15_yrfwd"
Iteration <- 1
like_dir <- file.path(main.dir, em_I, Iteration, "em", "likelihood_prof")
dir.create(like_dir)
files <- c("ss3.dat", "control.ss_new", "starter.ss", "forecast.ss", "ss.par", "ss3.exe")
file.copy(from = file.path(main.dir, em_I, Iteration,"em", files), to = like_dir, overwrite = T)
CTL <- SS_readctl_3.30(file = file.path(like_dir, "control.ss_new"), datlist = file.path(like_dir, "ss3.dat"))
CTL <- SS_readctl_3.30(file = file.path(main.dir, em_I, Iteration, "em", "control.ss_new"), datlist = file.path(main.dir, em_I, Iteration, "em", "ss3.dat"))
# r0 <- CTL$SR_parms$INIT[1]
# r0_vec <- seq(r0 - 1, r0 + 1, by = 0.2)
CTL$F_setup2

par.file <- SS_readpar_3.30(parfile = file.path(like_dir, "ss.par"), datsource = file.path(like_dir, "ss3.dat"), ctlsource = file.path(like_dir, "control.ss_new"))
F_term <- par.file$F_rate %>% filter(fleet == 1 & year == nyears) %>% pull(F)
F_term_vec <- seq(F_term - .01, F_term + 0.1, by = 0.005)

START <- SS_readstarter(file = file.path(like_dir, "starter.ss"), verbose = FALSE)
START$prior_like <- 1
START$ctlfile <- "control_modified.ss"
START$init_values_src <- 1
SS_writestarter(START, dir = like_dir, overwrite = TRUE, verbose = F)

likes <- profile_F(
  dir = like_dir,
  newctlfile = "control_modified.ss",
  linenum = nyears,
  #string = "Fvalue",
  profilevec = F_term_vec[10:20],
  usepar = T,
  parstring = "# F_rate[90]:",
  exe = "ss3",
  verbose = FALSE,
  extras="-nohess -nox"
)



likes <- profile(
  dir = like_dir,
  newctlfile = "control_modified.ss",
  linenum = 241,
  #string = "Fvalue",
  profilevec = F_term_vec,
  usepar = T,
  parstring = "# F_rate[90]:",
  exe = "ss3",
  verbose = FALSE,
  extras="-nohess -nox"
)

profile_mods <- SSgetoutput(dirvec = like_dir, keyvec = c(1:5,7,10))
profile_mods_sum <- SSsummarize(profile_mods)
profile_mods_sum$maxgrad <= 1e-4

SSplotProfile(profile_mods_sum,
  profile.string = "SR_LN",
  profile.label = "SR_LN(R0)",
  print = TRUE,
  plotdir = like_dir,

)
PinerPlot(profile_mods_sum, component = "Length_like", print = TRUE, plotdir = like_dir)
PinerPlot(profile_mods_sum, component = "Surv_like")




```

```{r}
#===========Run profile on R0======================================
R0.range    <- seq(3.8,5,by=0.1)
dir_profile <- file.path(root_dir,"01_SS final","00_Test")

# run profile in parallel
ncores <- parallelly::availableCores(omit = 1)
future::plan(future::multisession, workers = ncores)
prof.table <- profile(
  dir = dir_profile,
  oldctlfile = "control.ss",
  newctlfile = "control_modified.ss",
  string = "SR_LN(R0)", # subset of parameter label
  profilevec = R0.range, exe="ss_opt_win",
  usepar=F,parstring = "# SR_parm[1]:",
  extras="-nohess -nox")
future::plan(future::sequential)

# read the output files (with names like Report1.sso, Report2.sso, etc.)
profilemodels <- SSgetoutput(dirvec = dir_profile, keyvec = 1:length(R0.range))

# Add model with the profile parameter estimated
MLEmodel               <- SS_output(dir_profile, verbose = FALSE, printstats = FALSE)
profilemodels[["MLE"]] <- MLEmodel
profilesummary         <- SSsummarize(profilemodels)

# plot profile using summary created above
results <- SSplotProfile(profilesummary, # summary object
                         profile.string = "R0", # substring of profile parameter
                         profile.label = "Stock-recruit steepness (h)")

```

## DEPRECATED CODE

### Create vectors of F values for OMs
```{r}
#| eval: false
#Model estimated Fs
rep <- SS_output(dir = file.path(main.dir, "models", "03-simplified-mod"))
#SS_plots(rep)

F_comm_mod <- rep$exploitation$Comm[-1]
F_noncomm_mod <- rep$exploitation$Non_comm[-1]

#create descreasing F trajectories
f_dec <- getFhist(nsim=10,Esd=0.1,nyears=75,dFmin=-0.2,dFmax=0.2,bb=0.2,scale= 0.04)
f_dec_rescale <- apply(f_dec, 1, FUN = function(x)(scales::rescale(x, to = c(0.0325262, 0.08221600)))) #put on a similar scale to real F
# png(filename = file.path(main.dir, "Model_Runs", "fid_example.png"),width=10,height=8,units="in",res=450,pointsize = 12)
matplot(x=seq(1,75,1),(f_dec_rescale),type='l',ylim=c(0,0.1),xlab="",ylab="Fishing mortality", lwd = 3,cex.lab=1.5,cex.axis=1.5, col = 1:10)
# legend("topleft", legend = seq(1,10), col = 1:10, lty = 1, cex = 1.5)
# dev.off()

#create idc F trajectories
# log_sd <- 0.2
# sqrt(exp(log_sd**2)-1)
first_part <- sin_func(nyears = 60, low = 3*pi/2, high = 3*pi, Esd = 0.2)
second_part <- sin_func(nyears = 20, low = pi, amplitude = 0.5, Esd = 0.2)[2:16]
F_comm <- scales::rescale(c(first_part, second_part), to = c(0.0101208, 0.0868887)) #put on a similar scale to real F
# plot(x = seq(1,75), y = fsin, type = "l")
u_vec <- c(rep(1.8, 26), rep(1.47, 29), rep(1.03, 20))
F_noncomm <- u_vec * F_comm
#png(filename = file.path(main.dir, "Model_Runs", "fidi_example.png"),width=10,height=8,units="in",res=450,pointsize = 12)
plot(x = 1:75, y = F_comm, type = "l", ylim = c(0,0.15), ylab = "F", xlab = "Year")
lines(x = 1:75, y = F_noncomm, col = "blue")
lines(x = 1:75, y = F_comm_mod, lty = 2)
lines(x = 1:75, y = F_noncomm_mod, col = "blue", lty = 2)
legend("topleft", lty = c(1,1,2,2), col = c("black", "blue", "black", "blue"), legend = c("Commercial simulated", "Non-commercial simulated", "Commercial model", "Non-commerical model"))
#dev.off()

## creating multiple fsin vectors 
F_vec_mat <- matrix(NA, nrow = niter, ncol = 75)
for(i in 1:niter) {

first_part <- sin_func(nyears = 60, low = 3*pi/2, high = 3*pi, Esd = 0.2)
second_part <- sin_func(nyears = 20, low = pi, amplitude = 0.5, Esd = 0.2)[2:16]
F_comm <- scales::rescale(c(first_part, second_part), to = c(0.0101208, 0.0868887)) 

F_vec_mat[i,] <- F_comm

}
#png(filename = file.path(main.dir, "Model_Runs", "fidi_example.png"),width=10,height=8,units="in",res=450,pointsize = 12)
matplot(x = seq(1,75), y = t(F_vec_mat), type = "l", xlab = "Year", ylab = "F")
#dev.off()
#save(list = "F_vec_mat", file = file.path(main.dir, "Inputs", "Fsin_mat.RData"))
```

### Making random recdev vectors
```{r}
#| eval: false
sd_vec = c(0.52) #value from SS model  
# set.seed(731)
rdevs_array <- matrix(NA, nrow =125, ncol = niter) ## yrs x reps x sds
for(r in 1:ncol(rdevs_array)){ 
  # create single rep of correlated vectors given sd
  rdev_faux  <- faux::rnorm_multi(n = nrow(rdevs_array), ## year vector
                                 vars = 1,
                                 mu = 0,
                                 r = 1-1e-5,
                                 sd = sd_vec)
  rdevs_array[,r] <- rdev_faux$X1
                                 
 
}
# png(file.path(main.dir, "Model_Runs", '2024-08-12-rdevs_array-125yr.png'), height = 8, width =8, unit = 'in', res =400)
matplot(x = seq(1,125), y = rdevs_array, type = "l", lty = 1, lwd = 1.2)
abline(h = 0)
# dev.off()
round(mean(apply(rdevs_array,2,sd)),2) #check that SD makes sense
# save(list = "rdevs_array", file = file.path(main.dir, "Inputs", "recdevs_mat_125yrs.RData"))
```


### DEPRECATED: Loop to create OM and EMs
Maybe want to break this up so that creating the OMs first, then can create the EMs and sampling strategies. Especially for running on OSG, it will be better to have starting OMs and maybe EMs done already then can run the rest of simulation (feedback loop or just multiple scenarios)
```{r}
#| eval: false
file.list <- c("data.ss", "control.ss_new", "forecast.ss", "starter.ss", "ss_opt_win.exe")
for(i in 2:niter){
    om.dir <- dir.it.om[i]
    em.dir <- dir.it.em[i]

file.copy(file.path(main.dir, "models", "03-simplified-mod", "OM", file.list), om.dir, overwrite = TRUE) 
file.copy(file.path(main.dir, "models", "03-simplified-mod", "EM", file.list), em.dir, overwrite = TRUE)

## Start creating OM per iteration 
ss3sim::change_rec_devs(rdevs_array[-1,i], file.path(om.dir, "control.ss_new"), ctl_file_out = file.path(om.dir, "control.ss_new"))

dat <- r4ss::SS_readdat(
    file.path(om.dir, "data.ss"),
    verbose = FALSE
    )
ctl <- r4ss::SS_readctl(
    file.path(om.dir, "control.ss_new"),
    verbose = FALSE, use_datlist = TRUE, datlist = dat
    )

F_noncomm <- u_vec * F_vec_mat[i,]

ctl$F_Method <- 2
newctl <- ss3sim::change_f(years = list(1:75,1:75), fleets = c(1,2), fvals = list(F_vec_mat[i,], F_noncomm), ctl_list = ctl)
newctl$SR_parms$INIT[2] <- h_vec[2]
newctl$age_selex_types$Pattern <- 10
SS_writectl_3.30(newctl, outfile = file.path(om.dir, "control.ss"), overwrite = TRUE)

dat$catch$catch <- ifelse(dat$catch$catch == 0, 0, dat$catch$catch/dat$catch$catch)
##add dummy data for age comps
dat$agebin_vector <- seq(1,21)
dat$N_agebins <- length(dat$agebin_vector)
dat$N_ageerror_definitions <- 1
dat$ageerror <- matrix(data = c(rep(-1, 44), rep(0.001, 44)), nrow = 2, byrow = T)
dat$age_info <- data.frame("mintailcomp" = rep(-1,3), "addtocomp" = rep(1e-10,3), "combine_M_F" = 0, "CompressBins" = 0, "CompError" = 0, "ParmSelect" = 0, "minsamplesize" = 1)
dat$Lbin_method <- 3
dat$agecomp <- data.frame("Yr" = seq(1,75),
"Seas" = 1,
"FltSvy" = rep(3, 75),
"Gender" = 0,
"Part" = 0,
"Ageerr" = 1,
"Lbin_lo" = -1,
"Lbin_hi" = -1,
"Nsamp" = 10)
agecomp_mat <- as.data.frame(matrix(data = 1, nrow = nrow(dat$agecomp), ncol = dat$N_agebins))
dat$agecomp <- as.data.frame(cbind(dat$agecomp, agecomp_mat))
##add rows for earlier data for length comps 
xtra_lencomp <- data.frame("Yr" = seq(1,68),
"Seas" = 1,
"FltSvy" = rep(3, 68),
"Gender" = 0,
"Part" = 0,
"Nsamp" = 10)
lencomp_mat <-  as.data.frame(matrix(data = 1, nrow = nrow(xtra_lencomp), ncol = dat$N_lbins))
colnames(lencomp_mat) <- paste0("l", dat$lbin_vector)
xtra_lencomp <- cbind(xtra_lencomp, lencomp_mat)
dat$lencomp <- dat$lencomp %>% 
bind_rows(xtra_lencomp) %>% 
mutate(Seas = abs(Seas), FltSvy = abs(FltSvy)) %>% 
group_by(FltSvy) %>% 
arrange(Yr, FltSvy, .by_group = T) %>% 
as.data.frame()
SS_writedat_3.30(dat, outfile = file.path(om.dir, "data.ss"), overwrite = TRUE)

start <- SS_readstarter(file.path(om.dir, "starter.ss"))
start$datfile <- "data.ss"
start$ctlfile <- "control.ss"
start$run_display_detail <- 0
start$prior_like <- 0
start$last_estimation_phase <- 0
start$MCMCburn <- 0
start$MCMCthin <- 1
start$seed <- set.seed[1,1]
start$N_bootstraps <- 2
SS_writestarter(start, dir = om.dir, overwrite = TRUE)
#run ss to generate expected values for data
r4ss::run(dir = om.dir, exe = "ss_opt_win", extras = "-nohess", skipfinished = F)
## End of creating OM per iteration

## Start creating EMs per iteration
dat_exp <- SS_readdat_3.30(file.path(om.dir, "data_expval.ss"))
dat_samp <- ss3sim::sample_index(dat_exp, fleets = c(1,3), years = list(seq(1,75), seq(69,75)),
sds_obs = list(0.06, 0.25), seas = list(7,7))
dat_samp <- ss3sim::sample_catch(dat_samp) ##TODO: need to use u_vec to put in values for non_comm catch
dat_samp <- ss3sim::sample_lcomp(dat_samp, fleets = c(3), Nsamp = list(45), years = list(seq(69,75))) ##TODO: need to think more about Nsamp, cpar, and ESS
dat_samp <- ss3sim::sample_agecomp(dat_samp, fleets = c(3), Nsamp = list(45), years = list(seq(69,75))) 
SS_writedat_3.30(dat_samp, outfile = file.path(em.dir, "data.ss"), overwrite = TRUE)

ctl.em <- SS_readctl_3.30(file.path(em.dir, "control.ss_new"), use_datlist = TRUE, datlist = file.path(em.dir, "data.ss"))
#ctl.em$SR_parms #leave here as a reminder to change if needed if steepness is different
SS_writectl_3.30(ctl.em, outfile = file.path(em.dir, "control.ss"), overwrite = TRUE)

start <- SS_readstarter(file.path(em.dir, "starter.ss"))
start$datfile <- "data.ss"
start$ctlfile <- "control.ss"
start$N_bootstraps <- 1
SS_writestarter(start, dir = em.dir, overwrite = TRUE)

r4ss::run(dir = em.dir, exe = "ss_opt_win", skipfinished = F)

}

mods <- SSgetoutput(dirvec = c(
    file.path(main.dir, "opaka-sim", "1", "em"),
    file.path(main.dir, "opaka-sim", "2", "em"),
    file.path(main.dir, "opaka-sim", "3", "em"),
    file.path(main.dir, "opaka-sim", "5", "em"),
    file.path(main.dir, "models", "03-simplified-mod")
))
mods_sum <- SSsummarize(mods, verbose = F)
SSplotComparisons(mods_sum)
SSplotComparisons(mods_sum, legendlabels = c("em1", "em2", "em3", "em5", "simplified mod"))
length(which(mods_sum$maxgrad <= 1e-4))
SSplotData(mods$replist1)
SS_plots(mods$replist5)
##TODO: make plots to compare length and age comps across all iterations
mods_sum_sub <- SSsummarize(list(mods$replist2, mods$replist7))
SSplotComparisons(mods_sum_sub, legendlabels = c("EM", "OM"))
```


