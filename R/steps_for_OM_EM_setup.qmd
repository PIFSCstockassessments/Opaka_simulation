---
title: "Creating the OMs"
format: html
---


```{r}
library(r4ss)
library(tidyverse)
library(ss3sim)
library(stringr)
main.dir <- this.path::here(.. = 1)
source(file.path(main.dir, "R", "simF.r"))
source(file.path(main.dir, "R", "make_dummy_dat.r"))
source(file.path(main.dir, "R", "get_fits.r"))
set.seed <- read.csv(file.path(main.dir, "Inputs", "setseed.csv"))
sas_full <- read.csv(file.path(main.dir, "Inputs", "sas.csv"))
niter <- 100
rep <- SS_output(dir = file.path(main.dir, "models", "03-simplified-mod"))
```


### Create rec dev timeseries
Use estimated rec devs from "03-simplified-mod" but add some noise to the last 10 years. Then simulate future recruitment trajectories. Future_recdevs is stable recruitment devs centered around 0 with an sd of 0.16. Poor_recdevs simulates declining productivity by ~30% over the first 20 years and then stable, low productivity for the next 30 years. 
```{r}
recdevs_df <- rep$parameters %>% 
filter(str_detect(Label, "Rec")) %>% 
select(c(Label, Value)) %>% 
separate(col = Label, sep = "_", into = c("period", "recdev", "year")) 

plot(x = recdevs_df$year, y = recdevs_df$Value, type = "l")
sigmar <- .657 #from opaka model
new_recdevs <- matrix(data = NA, nrow = nrow(recdevs_df)+1, ncol = 100)
new_recdevs[1,] <- 0
for(i in 2:nrow(new_recdevs)){
    if(i < 60){
        recdev_sd <- .01
        new_recdevs[i,] <- faux::rnorm_multi(n = 100, ## year vector
                                 vars = 1,
                                 mu = recdevs_df$Value[i-1],
                                 r = 1-1e-5, #correlation
                                 sd = recdev_sd)[,1]
    }else{
        recdev_sd <- 0.14 #(sigmar^2/2 lognormal bias correction?)
        recdevs <- rnorm(n = 100, mean = 0, sd = sigmar)  
        new_recdevs[i,] <- sigmar * recdevs - sigmar^2 / 2 
        # new_recdevs[i,] <- faux::rnorm_multi(n = 100, ## year vector
        #                          vars = 1,
        #                          mu = 0,
        #                          r = 1-1e-5, #correlation
        #                          sd = recdev_sd)[,1]
    }


}
matplot(new_recdevs, type = "l")

# png(file.path(main.dir, "Model_Runs", '2024-12-03-rdevs_array.png'), height = 8, width =8, unit = 'in', res =400)
matplot(y = new_recdevs, type = "l", lty = 1, lwd = 1.2)
abline(h = 0)
#lines(x = 2:75, y = recdevs_df$Value, col = "red", lwd = 2, lty = 2)
# dev.off()
# save(list = "new_recdevs", file = file.path(main.dir, "Inputs", "recdevs_mat.RData"))

future_recdevs <- matrix(data = NA, nrow = 50, ncol = 100)
for(i in 1:nrow(future_recdevs)){ 
    recdevs <- rnorm(n = 100, mean = 0, sd = 0.)   
    future_recdevs[i,] <- sigmar * recdevs - sigmar^2 / 2 
}
matplot(y = future_recdevs, type = "l")

full_recdevs <- rbind(new_recdevs, future_recdevs)
# save(list = "full_recdevs", file = file.path(main.dir, "Inputs", "recdevs_mat.RData"))
matplot(y = full_recdevs, type = "l")

## years of poor recruitment in the future
poor_recdevs <- matrix(data = NA, nrow = 50, ncol = 100)
#vector of declining mu, declines by 40% over 25 years
mu.vec <- sort(stats::runif(n=20,min = -.40,max=0), decreasing =T)
recdev_sd <- .52 #half of sigmaR? Check about log scale
plot(x = 1:20, y = mu.vec, type = "l")
for(i in 1:nrow(poor_recdevs)){
    if(i <= 20){
        recdevs <- rnorm(n = 100, mean = mu.vec[i], sd = recdev_sd)  
        poor_recdevs[i,] <- recdev_sd * recdevs - recdev_sd^2 / 2 
        
    }else{
        recdevs <- rnorm(n = 100, mean = -.4, sd = recdev_sd)  
        poor_recdevs[i,] <- recdev_sd * recdevs - recdev_sd^2 / 2
    }

}

matplot(y = poor_recdevs, type = "l")
full_poor_recdevs <- rbind(new_recdevs, poor_recdevs) #same recdevs for years 1-75 as full_recdevs, then add poor recdevs for future
matplot(y = full_poor_recdevs, type = "l")
abline(h = 0)
abline(v=76)
abline(v=95)
# lines(x = 76:95, y = mu.vec, lty = 2, col = "red")
# save(list = "full_poor_recdevs", file = file.path(main.dir, "Inputs", "poor_recdevs_mat.RData"))

# recdev_sd <- 0.2
# poor_recdevs <- matrix(data = NA, nrow = 50, ncol = 100)
# for(i in 1:nrow(poor_recdevs)){ 
#     poor_recdevs[i,] <- faux::rnorm_multi(n = 100, ## year vector
#                                 vars = 1,
#                                 mu = -.2,
#                                 r = 1-1e-5, #correlation
#                                 sd = recdev_sd)[,1]
# }
# matplot(y = poor_recdevs, type = "l")
# abline(h = 0)

# full_poor_recdevs <- rbind(full_recdevs[1:75,], poor_recdevs) #same recdevs for years 1-75 as full_recdevs, then add poor recdevs for future
# matplot(y = full_poor_recdevs, type = "l")
# abline(h = 0)
# save(list = "full_poor_recdevs", file = file.path(main.dir, "Inputs", "poor_recdevs_mat.RData"))
```

## Simulating F trajectory
```{r}
for(i in 1:nrow(future_cf)){ 
    future_cf[i,] <- faux::rnorm_multi(n = 100, ## year vector
                                vars = 1,
                                mu = 0.0325262, # terminal year F from model
                                r = 1-1e-5, #correlation
                                sd = 0.0075)[,1]
}
matplot(y = future_cf, type = "l", lty = 1, lwd = 1.2)
F_comm_mod <- rep$exploitation$Comm[-1]
F_comm_df <- matrix(data = rep(F_comm_mod, 100), nrow = 75, ncol = 100,byrow = F)
F_comm_df <- rbind(F_comm_df, future_cf)
F_noncomm_mod <- rep$exploitation$Non_comm[-1]
F_noncomm_df <- matrix(data = rep(F_noncomm_mod, 100), nrow = 75, ncol = 100,byrow = F)
F_noncomm_df <- rbind(F_noncomm_df, future_cf * 1.03)
# save(list = c("F_noncomm_df", "F_comm_df"), file = file.path(main.dir, "Inputs", "constantF_mat.RData"))

## Increasing F
F_up_mu <- seq(F_comm_mod[75], 0.0491544, length.out = 20) #increase back up to 75 percentile of historical Fs
future_F_up <- matrix(data = NA, nrow = 50, ncol = 100)
for(i in 1:nrow(future_F_up)){
    if(i <=20){
         future_F_up[i, ] <- faux::rnorm_multi(n = 100, ## year vector
                                vars = 1,
                                mu = F_up_mu[i], # increasing F trajectory
                                r = 1-1e-5, #correlation
                                sd = 0.0015)[,1]
    }else{
        future_F_up[i, ] <- faux::rnorm_multi(n = 100, ## year vector
                            vars = 1,
                            mu = F_up_mu[20], # stay around the last year of increasing 
                            r = 1-1e-5, #correlation
                            sd = 0.0015)[,1]
    }

}
matplot(y = future_F_up, type = "l", lty = 1, lwd = 1.2)
F_comm_up <- rbind(F_comm_df, future_F_up)
F_noncomm_up <- rbind(F_noncomm_df, future_F_up * 1.03)
# save(list = c("F_noncomm_up", "F_comm_up"), file = file.path(main.dir, "Inputs", "increaseF_mat.RData"))
```

### Load already created RecDev-vectors and get F from simplified model
```{r}
F_comm_mod <- rep$exploitation$Comm[-1]
F_noncomm_mod <- rep$exploitation$Non_comm[-1]
load(file.path(main.dir, "Inputs", "recdevs_mat.RData"))
load(file.path(main.dir, "Inputs", "poor_recdevs_mat.RData"))
load(file.path(main.dir, "Inputs", "constantF_mat.RData"))
load(file.path(main.dir, "Inputs", "increaseF_mat.RData"))
```

### Create the directories for OSG and target_dir.txt

```{r}

library(fs)

scen <- "HRF_poorrec"
nyears_fwd <- 25
niter <- 100
scen_dirs <- file.path(main.dir, paste(scen, nyears_fwd, "yrfwd", sep = "_"), 1:niter)
sapply(scen_dirs, dir.create, recursive = T)
#file.copy(from = file.path(main.dir, "Inputs", "recdevs_mat.RData"), file.path(scen_dirs, "recdevs_mat.RData"))
file.copy(from = file.path(main.dir, "Inputs", "poor_recdevs_mat.RData"), file.path(scen_dirs, "poor_recdevs_mat.RData"))
file.copy(from = file.path(main.dir, "Inputs", "setseed.csv"), file.path(scen_dirs, "setseed.csv"))
file.copy(from = file.path(main.dir, "Inputs", "sas.csv"), file.path(scen_dirs, "sas.csv"))
file.copy(from = file.path(main.dir, "Inputs", "constantF_mat.RData"), file.path(scen_dirs, "constantF_mat.RData"))

for(i in 1:length(scen_dirs)){
    fs::dir_copy(file.path(main.dir, "models", paste0("opaka-om-", nyears_fwd)), scen_dirs[i]) #"-FRS-only" #, "-selex"
    fs::dir_copy(file.path(main.dir, "models", paste0("opaka-em-", nyears_fwd)), scen_dirs[i])
}
#only for FRS_only_poorrec_25_yrfwd scenario (testing hyperstablity)
# for(i in 1:length(scen_dirs)){
#     file.copy(from = file.path(main.dir, "FRS_only_25_yrfwd", i, "em", "ss3.dat"), 
#     to = file.path(scen_dirs[i], "normal_rec.dat"))
# }

for(i in 1:length(scen_dirs)){
    shell(paste0("powershell cd ", scen_dirs[i], ";tar -czf start.tar.gz ./*"))
    files_clean <- list.files(scen_dirs[i], pattern = ".csv|.RData|opaka-", full.names = T)
    unlink(files_clean, recursive = T)
}

target_dirs <- paste0(paste(scen, nyears_fwd, "yrfwd", sep = "_"), "/", 1:niter)
writeLines(target_dirs, file.path(main.dir, paste(scen, nyears_fwd, "yrfwd", sep = "_"), "target_dirs.txt"))
shell(paste0("powershell cd ", main.dir, ";tar -czf upload.", scen, "_25_yrsfwd.tar.gz ", scen, "_25_yrfwd/"))
#upload these files to OSG 
```

### Getting results  

```{r}
#get results out of models for comparisons
all_scenario_names <- paste(sas_full$Scen_name, sas_full$N_years, "yrfwd", sep = "_")

missing_vec <- c()
for(i in 1:length(all_scenario_names)){
    if(file.exists(file.path(main.dir, paste0("download.", sas_full$Scen_name[i], "_25_yrfwd.tar.gz ")))){
            shell(paste0("powershell cd ", main.dir, ";tar -xzf download.", sas_full$Scen_name[i], "_25_yrfwd.tar.gz ", sas_full$Scen_name[i], "_25_yrfwd/"))
            for(y in 1:niter){
                if(file.exists(file.path(main.dir, paste0(sas_full$Scen_name[i], "_25_yrfwd/"), y, "End.tar.gz"))){
                    shell(paste0("powershell cd ", main.dir, "/", sas_full$Scen_name[i], "_25_yrfwd/", y, ";tar -xzf End.tar.gz"))
                }else{
                    missing_vec <- c(missing_vec, paste0(sas_full$Scen_name[i], "_25_yrfwd/", y))
                } 
            }
    }else{
        next
    }

}

get_results_all(
    overwrite_files = T,
    user_scenarios =  all_scenario_names[8],
    filename_prefix = "HRF_poorrec"
)   
get_fits_all(
    overwrite_files = T,
    user_scenarios = all_scenario_names[8], #all_scenario_names,
    filename_prefix = "HRF_poorrec"
)

```


### Checking results

```{r}

rep <- SS_output(file.path(main.dir, "SQ_0_yrfwd", "1", "em"))
SS_plots(rep)
reps <- SSgetoutput(dirvec = c(#file.path(main.dir, "SQ_15_yrfwd", "1", "om"),
file.path(main.dir, "IRF_Selex_25_yrfwd", "1", "om"),
file.path(main.dir, "IRF_Selex_25_yrfwd", "1", "em")
))

rep_1 <- SS_output(dir = dir, covar = FALSE, verbose = FALSE,
    forecast = forecastTF, warn = FALSE,
    readwt = FALSE, printstats = FALSE, NoCompOK = TRUE)
reps <- SSgetoutput(dirvec = c(
file.path(main.dir, "HRF_SQ_25_yrfwd", "2", "om"),
file.path(main.dir, "HRF_SQ_25_yrfwd", "2", "em"),
file.path(main.dir, "HRF_poorrec_25_yrfwd", "2", "om"),
file.path(main.dir, "HRF_poorrec_25_yrfwd", "2", "em")
))

reps_sum <- SSsummarize(reps)
SSplotComparisons(reps_sum, legendlabels = c("SQ_om", "SQ_em", "PR_om", "PR_em"))
SSplotComparisons(reps_sum, models = c(1,2), legendlabels = c("SQ_om", "SQ_em"), uncertainty = F, xlim = c(75,76))
SS_plots(reps$replist4)
SS_plots(reps$replist2)

reps$replist2$breakpoints_for_bias_adjustment_ramp
new_bias <- SS_fitbiasramp(reps$replist4)

reps_sum$indices %>% filter(Fleet == 3) %>% #filter(name == "replist1" | name == "replist2") %>%
mutate(name = recode(name, 
                    replist1 = "om_1", 
                    replist2 = "em_1", 
                    replist3 = "om_2",
                    replist4 = "em_2",
                    replist5 = "om_3",
                    replist6 = "em_3",
                    replist7 = "om_4",
                    replist8 = "em_4",
                    replist9 = "om_5",
                    replist10 = "em_5"
                    )) %>%
separate(name, sep = "_", into = c("mod_type", "rep")) %>%
ggplot(aes(x = Yr)) +
geom_point(data = . %>% filter(mod_type == "om"), aes(y = Exp, color = mod_type)) + 
geom_point(data = . %>% filter(mod_type == "em"), aes(y = Obs, color = mod_type)) + 
geom_line(data = . %>% filter(mod_type == "em"), aes(y = Exp, color = mod_type), linewidth = 1.5) +
facet_wrap(~rep) +
labs(x = "Year", y = "BFISH Index") + 
theme_classic() +
theme(legend.position = "top",
legend.text = element_text(size = 12))

```


Questions from Punt et al. 2021 to think about for this project:
1. How does the ability to estimate quantities of management interest change with average annual (effective) sample sizes for length-comp and conditional age-length data? 
2. Does including data sources with small sample sizes in an assessment lead to bias? 
3. What are the implications of collecting length and age samples at intervals greater than one year but large sample sizes?
4. How does the assessment performance change if sampling is unbalanced over time and space?
Questions from Ono et al. 2015
1. What is the value of age vs length composition data? 
2. What is the influence of age composition collection frequency and duration?
3. What is the influence of frequency and duration of survey composition data?
4. What is the impact of historical fishery composition data? 
5. What is the impact of composition data sample size? 
6. Which fishing pattern produces the most informative data? 


### Run likelihood profiles
To profile over an F value for a given year, use the following code: 

```{r}
em_I <- "SQ_0_yrfwd"
Iteration <- 5
nyears <- 75
like_dir <- file.path(main.dir, em_I, Iteration, "em", "likelihood_prof")
dir.create(like_dir)
files <- c("ss3.dat", "control.ss_new", "starter.ss", "forecast.ss")
file.copy(from = file.path(main.dir, em_I, Iteration,"em", files), to = like_dir, overwrite = T)
file.copy(from = file.path(main.dir, "bin", "ss3_win.exe"), to = like_dir, overwrite = T)
## Create fvec of values to profile over
rep_tmp <- SS_output(file.path(main.dir, em_I, Iteration, "em"), verbose = F)
fest <- rep_tmp$exploitation %>% filter(Yr == nyears) %>% pull(Comm)
fvec <- seq(fest - 0.01, fest + 0.02, by = 0.001)
fdf <- rep_tmp$exploitation %>% 
select(Yr, Seas, Comm, Non_comm) %>%
pivot_longer(cols = c("Comm", "Non_comm")) %>% 
mutate(Fleet = recode(name, Comm = "1", Non_comm = "2"),
Fleet = as.numeric(Fleet),
se = 0.5,
phase = -1) %>%
filter(Yr > 0) %>%
arrange(Fleet, Yr) %>% 
select(Fleet, Yr, Seas, value, se, phase) 

## Fix selex first 
CTL <- SS_readctl_3.30(file.path(like_dir, "control.ss_new"), datlist = file.path(like_dir, "ss3.dat"))
CTL$size_selex_parms$PHASE <- abs(CTL$size_selex_parms$PHASE) * -1
SS_writectl_3.30(CTL, outfile = file.path(like_dir, "control.ss_new"), overwrite = T)
rm(CTL)
## read in ctl file
CTL <- readLines(file.path(like_dir, "control.ss_new"))
# selex_lines <- grep("#_SizeSelex", CTL)
# end_selex_lines <- grep("#_AgeSelex", CTL)
# selex_params <- CTL[(selex_lines+2):(end_selex_lines-1)]
# selex <- strsplit(selex_params, " ")
# selex_new <- list()
# for(i in 1:length(selex)){
#     ind <- which(selex[[i]] == 3)
#     if(length(ind) == 1){
#         selex[[i]][ind] <- "-3"
#     }
#     selex[[i]] <- selex[[i]][-which(selex[[i]] == "")]
#     selex_new[[i]] <- str_flatten(selex[[i]], collapse =  " ")
# }
# ## replace selex values
# CTL[237] <- selex_new[[1]]
# CTL[238] <- selex_new[[2]]
# CTL[239] <- selex_new[[3]]
# CTL[240] <- selex_new[[4]]
# CTL[241] <- selex_new[[5]]
# CTL[242] <- selex_new[[6]]

## find lines where to break the file and insert new lines
start_ind <- grep("#Fishing Mortality info", CTL)
end_ind <- grep("#_initial_F_parms", CTL)

f_setup <- paste0("## add new fishing mortality info \n",
"#Fishing Mortality info \n",
"0.3 # F ballpark value in units of annual_F \n",
"-2001 # F ballpark year (neg value to disable) \n",
"4 # F_Method:  1=Pope midseason rate; 2=F as parameter; 3=F as hybrid; 4=fleet-specific parm/hybrid (#4 is superset of #2 and #3 and is recommended) \n",
"2.9 # max F (methods 2-4) or harvest fraction (method 1) \n",
"#fleet parameter_value phase \n",
"1 0.015 1 \n",
"2 0.015 1 \n",
"-9998 1 1 \n",
"3 #Ntuning loops \n",
"# detailed setup for F_Method=2; -Yr to fill remaining years \n",
"#Fleet Yr Seas F_value se phase \n")

f_detailed_ender <- " -9999 1 1 1 1 1 \n"


## write out new ctl file
writeLines(CTL[1:(start_ind -1)], file.path(like_dir, "control_modified.ss"))
CON <- file(file.path(like_dir, "control_modified.ss"), "a")
cat(f_setup, file = CON)
write.table(fdf, file = CON, append = T, col.names = F, row.names = F)
cat(f_detailed_ender, file = CON) 
writeLines(CTL[end_ind:length(CTL)], CON)
close(CON)

#adjust se for catch 
dat <- SS_readdat_3.30(file = file.path(like_dir, "ss3.dat"), verbose = F)
dat$catch$catch_se <- .5
SS_writedat(dat, outfile = file.path(like_dir, "ss3.dat"), overwrite = T)
## Create profile directories
profile_dirs <- paste0(like_dir, "/profile_", seq(1,length(fvec)))
sapply(profile_dirs, dir.create)
profile.files <- c("ss3.dat", "control_modified.ss", "starter.ss", "forecast.ss", "ss3_win.exe")
for (i in 1:length(fvec)){
    file.copy(from = file.path(like_dir, profile.files), to = profile_dirs[i], overwrite = T)

    CTL <- readLines(file.path(profile_dirs[i], "control_modified.ss"))
    line_ind <- grep(paste0("1 ",nyears, " 1"), CTL)
    CTL[line_ind] <- paste0("1 ", nyears, " 1 ", fvec[i], " 0.5 -1")
    writeLines(CTL, file.path(profile_dirs[i], "control_modified.ss"))

    START <- SS_readstarter(file.path(profile_dirs[i], "starter.ss"))
    START$ctlfile <- "control_modified.ss"
    START$prior_like <- 1
    START$init_values_src <- 0
    SS_writestarter(START, profile_dirs[i], overwrite = T)

    run(dir = profile_dirs[i], exe = "ss3_win.exe", extras = "-nohess", skipfinished = F, verbose = F)

}



```



```{r}
#em_I <- paste0("em_", n_yrs_fwd)
em_I <- "HRFhyperstable_15_yrfwd"
Iteration <- 1
like_dir <- file.path(main.dir, em_I, Iteration, "em", "likelihood_prof")
dir.create(like_dir)
files <- c("ss3.dat", "control.ss_new", "starter.ss", "forecast.ss", "ss.par", "ss3.exe")
file.copy(from = file.path(main.dir, em_I, Iteration,"em", files), to = like_dir, overwrite = T)
CTL <- SS_readctl_3.30(file = file.path(like_dir, "control.ss_new"), datlist = file.path(like_dir, "ss3.dat"))
CTL <- SS_readctl_3.30(file = file.path(main.dir, em_I, Iteration, "em", "control.ss_new"), datlist = file.path(main.dir, em_I, Iteration, "em", "ss3.dat"))
# r0 <- CTL$SR_parms$INIT[1]
# r0_vec <- seq(r0 - 1, r0 + 1, by = 0.2)
CTL$F_setup2

par.file <- SS_readpar_3.30(parfile = file.path(like_dir, "ss.par"), datsource = file.path(like_dir, "ss3.dat"), ctlsource = file.path(like_dir, "control.ss_new"))
F_term <- par.file$F_rate %>% filter(fleet == 1 & year == nyears) %>% pull(F)
F_term_vec <- seq(F_term - .01, F_term + 0.1, by = 0.005)

START <- SS_readstarter(file = file.path(like_dir, "starter.ss"), verbose = FALSE)
START$prior_like <- 1
START$ctlfile <- "control_modified.ss"
START$init_values_src <- 1
SS_writestarter(START, dir = like_dir, overwrite = TRUE, verbose = F)

likes <- profile_F(
  dir = like_dir,
  newctlfile = "control_modified.ss",
  linenum = nyears,
  #string = "Fvalue",
  profilevec = F_term_vec[10:20],
  usepar = T,
  parstring = "# F_rate[90]:",
  exe = "ss3",
  verbose = FALSE,
  extras="-nohess -nox"
)



likes <- profile(
  dir = like_dir,
  newctlfile = "control_modified.ss",
  linenum = 241,
  #string = "Fvalue",
  profilevec = F_term_vec,
  usepar = T,
  parstring = "# F_rate[90]:",
  exe = "ss3",
  verbose = FALSE,
  extras="-nohess -nox"
)

profile_mods <- SSgetoutput(dirvec = like_dir, keyvec = c(1:5,7,10))
profile_mods_sum <- SSsummarize(profile_mods)
profile_mods_sum$maxgrad <= 1e-4

SSplotProfile(profile_mods_sum,
  profile.string = "SR_LN",
  profile.label = "SR_LN(R0)",
  print = TRUE,
  plotdir = like_dir,

)
PinerPlot(profile_mods_sum, component = "Length_like", print = TRUE, plotdir = like_dir)
PinerPlot(profile_mods_sum, component = "Surv_like")




```
